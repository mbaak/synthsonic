{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdgym import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthsonic.models.kde_utils import kde_smooth_peaks_1dim, kde_smooth_peaks\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('alarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data, categorical_columns, ordinal_columns = load_dataset('alarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pgmpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import TreeSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import HillClimbSearch, BicScore, ExhaustiveSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.columns = [str(i) for i in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# learn graph structure \n",
    "est = TreeSearch(df, root_node=df.columns[0])\n",
    "dag = est.estimate(estimator_type=\"tan\", class_node='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# alternative graph structure \n",
    "est2 = TreeSearch(df, root_node=df.columns[0])\n",
    "dag2 = est2.estimate(estimator_type=\"chow-liu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = HillClimbSearch(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = est.estimate() # start_dag=dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(best_model, with_labels=True, arrowsize=30, node_size=800, alpha=0.3, font_weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = best_model.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import BayesianEstimator\n",
    "\n",
    "# there are many choices of parametrization, here is one example\n",
    "model = BayesianModel(best_model.edges())\n",
    "model.fit(df, estimator=BayesianEstimator, prior_type='dirichlet', pseudo_counts=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_cpds('2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up train-test sample.\n",
    "# the test sample is used to calibrate the output of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(data, np.ones(data.shape[0]), test_size=0.35,\n",
    "                                                        random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=MLPClassifier(random_state=0, max_iter=1000, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(\n",
    "    n_estimators=250,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    max_depth=9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argspecs = inspect.getfullargspec(clf.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_weight = 'sample_weight' in argspecs.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_one = len(X1_train)\n",
    "n_zero = n_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.sampling import BayesianModelSampling\n",
    "\n",
    "# sample data from BN\n",
    "inference = BayesianModelSampling(model)\n",
    "df_data = inference.forward_sample(size=n_zero, return_type='dataframe', seed=0)\n",
    "\n",
    "df_data.columns = [int(c) for c in df_data.columns]\n",
    "\n",
    "X0_train = df_data[sorted(df_data.columns)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = np.zeros(n_zero)\n",
    "ones = np.ones(n_one)\n",
    "\n",
    "yy = np.concatenate([zeros, ones], axis = 0)\n",
    "XX = np.concatenate([X0_train, X1_train], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(XX, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = clf.predict_proba(X0_train)[:, 1]\n",
    "p2 = clf.predict_proba(X1_train)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 100\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.hist(p0, bins=100, range=(0,1), alpha=0.5, log=True, density=True)\n",
    "plt.hist(p2, bins=100, range=(0,1), alpha=0.5, log=True, density=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the probabilities, using the test sample and a new null sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = inference.forward_sample(size=100000, return_type='dataframe', seed=10)\n",
    "\n",
    "df_data.columns = [int(c) for c in df_data.columns]\n",
    "\n",
    "X = df_data[sorted(df_data.columns)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = clf.predict_proba(X)[:, 1]\n",
    "p2 = clf.predict_proba(X1_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 100\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.hist(p0, bins=100, range=(0,1), alpha=0.5, log=True, density=True)\n",
    "plt.hist(p2, bins=100, range=(0,1), alpha=0.5, log=True, density=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.5 / np.power(3500, 1/3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 100\n",
    "binning = np.linspace(0, 1, nbins+1)\n",
    "\n",
    "hist_p0, bin_edges = np.histogram(p0, binning)\n",
    "hist_p1, bin_edges = np.histogram(p2, binning)\n",
    "\n",
    "\n",
    "hist_p0\n",
    "\n",
    "hist_p1\n",
    "\n",
    "def poisson_uncertainty(n):\n",
    "    sigman = np.sqrt(n)\n",
    "    # correct poisson counts of zero.\n",
    "    sigman[sigman == 0] = 1.\n",
    "    return sigman\n",
    "\n",
    "def fraction_and_uncertainty(a, b, sigma_a, sigma_b):\n",
    "    frac_a = a / (a + b)\n",
    "    frac_b = b / (a + b)\n",
    "    sigma_fa2 = np.power(frac_b * sigma_a, 2) / np.power(a + b, 2)  +  np.power(frac_a * sigma_b, 2) / np.power(a + b, 2)\n",
    "    return frac_a, np.sqrt(sigma_fa2)\n",
    "\n",
    "rest_p0 = np.sum(hist_p0) - hist_p0\n",
    "rest_p1 = np.sum(hist_p1) - hist_p1\n",
    "\n",
    "sigma_bin0 = poisson_uncertainty(hist_p0)\n",
    "sigma_rest0 = poisson_uncertainty(rest_p0)\n",
    "\n",
    "sigma_bin1 = poisson_uncertainty(hist_p1)\n",
    "sigma_rest1 = poisson_uncertainty(rest_p1)\n",
    "\n",
    "frac0, sigma_frac0 = fraction_and_uncertainty(hist_p0, rest_p0, sigma_bin0, sigma_rest0)\n",
    "frac1, sigma_frac1 = fraction_and_uncertainty(hist_p1, rest_p1, sigma_bin1, sigma_rest1)\n",
    "\n",
    "p1calib, sigma_p1calib = fraction_and_uncertainty(frac1, frac0, sigma_frac1, sigma_frac0)\n",
    "\n",
    "sample_weight = 1 / (sigma_p1calib * sigma_p1calib)\n",
    "\n",
    "min(sample_weight)\n",
    "\n",
    "sample_weight /= min(sample_weight)\n",
    "\n",
    "sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.isotonic import IsotonicRegression\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we recalibrate per probability bin. NO interpolation (not valid in highest bin)\n",
    "\n",
    "hist_p0, bin_edges = np.histogram(p0, bins=nbins, range=(0, 1))\n",
    "hist_p1, bin_edges = np.histogram(p2, bins=nbins, range=(0, 1)) #### !!!! p2\n",
    "bin_centers = bin_edges[:-1] + 0.5/nbins\n",
    "\n",
    "hnorm_p0 = hist_p0 / sum(hist_p0)\n",
    "hnorm_p1 = hist_p1 / sum(hist_p1)\n",
    "hnorm_sum = hnorm_p0 + hnorm_p1\n",
    "p1cb = np.divide(hnorm_p1, hnorm_sum, out=np.zeros_like(hnorm_p1), where=hnorm_sum != 0)\n",
    "# self.p1cb = p1cb, bin_centers\n",
    "\n",
    "# use isotonic regression to smooth out potential fluctuations in the p1 values\n",
    "# isotonic regression assumes that p1 can only be a rising function.\n",
    "# Iâ€™m assuming that if a classifier predicts a higher probability, the calibrated probability\n",
    "# will also be higher. This may not always be right, but I think generally it is a safe one.\n",
    "iso_reg = IsotonicRegression(y_min=0, y_max=1).fit(bin_centers, p1calib, sample_weight)\n",
    "p1pred = iso_reg.predict(bin_centers)\n",
    "\n",
    "p1f_ = interpolate.interp1d(bin_edges[:-1], p1pred, kind='previous', bounds_error=False, fill_value=\"extrapolate\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1lin = p1f_(bin_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "#plt.plot(bin_centers, p1cb)\n",
    "plt.plot(bin_centers, p1cb)\n",
    "plt.plot(bin_centers, bin_centers)\n",
    "plt.plot(bin_centers, p1lin)\n",
    "#plt.plot(bin_centers, p2lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.95,1,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = p1f_(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "#plt.plot(bin_centers, p1cb)\n",
    "plt.plot(x, pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxp1 = p1f_(0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_weight = maxp1 / (1. - maxp1)\n",
    "max_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation - part 1: check if reweighting works okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.sampling import BayesianModelSampling\n",
    "\n",
    "# sample data from BN\n",
    "inference = BayesianModelSampling(model)\n",
    "\n",
    "df_data = inference.forward_sample(size=250000, return_type='dataframe', seed=1)\n",
    "\n",
    "df_data.columns = [int(c) for c in df_data.columns]\n",
    "\n",
    "X = df_data[sorted(df_data.columns)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = clf.predict_proba(X)[:, 1]\n",
    "nominator = p1f_(p0)\n",
    "denominator = 1 - nominator\n",
    "weight = np.divide(nominator, denominator, out=np.ones_like(nominator), where=denominator != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), sum(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum(weight * weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(weight[weight < 10], bins=100, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = clf.predict_proba(X)[:, 1]\n",
    "nominator = p1f_(p0)\n",
    "denominator = 1 - nominator\n",
    "weight = np.divide(nominator, denominator, out=np.ones_like(nominator), where=denominator != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data, sample_weights = self._sample_no_transform(n_samples, random_state)\n",
    "pop = np.asarray(range(X.shape[0]))\n",
    "probs = weight/np.sum(weight)\n",
    "sample = choices(pop, probs, k=X.shape[0])\n",
    "Xtrans = X[sample]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = clf.predict_proba(Xtrans)[:, 1]\n",
    "p2 = clf.predict_proba(X1_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.hist(p0, bins=100, range=(0,1), alpha=0.5, density=True, log=True) #, weights=weight)#, log=True)\n",
    "plt.hist(p2, bins=100, range=(0,1), alpha=0.5, density=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation - part 2: plot distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.hist(X[:, i], bins=100, range=(0,1), alpha=0.5, density=True)#, log=True)\n",
    "plt.hist(X1_test[:, i], bins=100, range=(0,1), alpha=0.5, density=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation part 3: check number of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = inference.forward_sample(size=500000, return_type='dataframe', seed=2)\n",
    "df_data.columns = [int(c) for c in df_data.columns]\n",
    "X10k = df_data[sorted(df_data.columns)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = clf.predict_proba(X10k)[:, 1]\n",
    "nominator = p1f_(p0)\n",
    "denominator = 1 - nominator\n",
    "weight = np.divide(nominator, denominator, out=np.ones_like(nominator), where=denominator != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum(weight * weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uo, co = np.unique(X10k, axis=0, return_counts=True)\n",
    "countso = np.sort(co)[::-1] / 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = np.asarray(range(X10k.shape[0]))\n",
    "probs = weight/np.sum(weight)\n",
    "sample = choices(pop, probs, k=X10k.shape[0])\n",
    "Xtrans = X10k[sample]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, c = np.unique(Xtrans, axis=0, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.sort(c)[::-1] / 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, c = np.unique(data, axis=0, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = np.sort(c)[::-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.bar(list(range(40)), c2[:40], alpha=0.3)\n",
    "plt.bar(list(range(40)), counts[:40], alpha=0.3)\n",
    "plt.bar(list(range(40)), countso[:40], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.bar(list(range(40)), c2[:40], alpha=0.3)\n",
    "plt.bar(list(range(40)), counts[:40], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.bar(list(range(40)), c2[:40], alpha=0.3)\n",
    "plt.bar(list(range(40)), counts[:40], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sdgym import benchmark\n",
    "from sdgym import load_dataset\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from synthsonic.models.kde_copula_nn_pdf import KDECopulaNNPdf\n",
    "from synthsonic.models.categorical_utils import categorical_round, vec_translate, categorical_frequency_mapping, \\\n",
    "            categorical_frequency_inverse_mapping, encode_one_hot, decode_one_hot\n",
    "from timeit import default_timer as timer\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(Xtrans)\n",
    "df.to_csv('test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KDECopulaNNPdf_RoundCategorical(real_data, categorical_columns, ordinal_columns, times=None):\n",
    "    df = pd.read_csv('test.csv')\n",
    "    data = df.values[:25000]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alarm_times = []\n",
    "alarm_thing = partial(KDECopulaNNPdf_RoundCategorical, times=alarm_times)\n",
    "alarm_thing.__name__ = KDECopulaNNPdf_RoundCategorical.__name__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alarm_scores = benchmark(synthesizers=[alarm_thing], datasets=['alarm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alarm_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    alarm_scores = benchmark(synthesizers=[alarm_thing], datasets=['alarm'])\n",
    "    alarm_scores.drop(columns=['timestamp'], inplace=True)\n",
    "    exec_time = ['N/A'] * 9 + [round(np.mean(alarm_times), 2)]\n",
    "    alarm_scores['alarm/exec_time(s)'] = exec_time    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
