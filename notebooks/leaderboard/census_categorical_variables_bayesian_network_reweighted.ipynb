{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U git+https://github.com/sbrugman/SDGym.git@v0.2.2-hw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "from functools import partial\n",
    "from random import choices\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sdgym\n",
    "from sdgym import load_dataset\n",
    "from sdgym import benchmark\n",
    "from sdgym import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pgmpy\n",
    "\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import TreeSearc, HillClimbSearch, BicScore, ExhaustiveSearch, BayesianEstimator\n",
    "from pgmpy.sampling import BayesianModelSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.isotonic import IsotonicRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthsonic.models.kde_utils import kde_smooth_peaks_1dim, kde_smooth_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'census_categorical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, categorical_columns, ordinal_columns = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.columns = [str(i) for i in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn graph structure (preferred - fast)\n",
    "est = TreeSearch(df, root_node=df.columns[0])\n",
    "# FIXME: 'label' column\n",
    "dag = est.estimate(estimator_type=\"tan\", class_node='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative graph structure \n",
    "if False:\n",
    "    est2 = TreeSearch(df, root_node=df.columns[0])\n",
    "    dag2 = est2.estimate(estimator_type=\"chow-liu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative graph structure (slow)\n",
    "if False:\n",
    "    est = HillClimbSearch(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = est.estimate() # start_dag=dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(best_model, with_labels=True, arrowsize=30, node_size=800, alpha=0.3, font_weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = best_model.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are many choices of parametrization, here is one example\n",
    "model = BayesianModel(best_model.edges())\n",
    "model.fit(df, estimator=BayesianEstimator, prior_type='dirichlet', pseudo_counts=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_cpds('2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up train-test sample.\n",
    "# the test sample is used to calibrate the output of the classifier\n",
    "\n",
    "random_state = 0\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(data, np.ones(data.shape[0]), test_size=0.35,\n",
    "                                                        random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "clf = MLPClassifier(random_state=0, max_iter=1000, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(\n",
    "    n_estimators=250,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    max_depth=9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_one = len(X1_train)\n",
    "n_zero = n_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed = 0)\n",
    "\n",
    "# sample data from BN\n",
    "inference = BayesianModelSampling(model)\n",
    "df_data = inference.forward_sample(size=n_zero, return_type='dataframe')\n",
    "\n",
    "df_data.columns = [int(c) for c in df_data.columns]\n",
    "\n",
    "X0_train = df_data[sorted(df_data.columns)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = np.zeros(n_zero)\n",
    "ones = np.ones(n_one)\n",
    "\n",
    "yy = np.concatenate([zeros, ones], axis = 0)\n",
    "XX = np.concatenate([X0_train, X1_train], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(XX, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the probabilities, using the test sample and a new null sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "df_data = inference.forward_sample(size=250000, return_type='dataframe')\n",
    "\n",
    "df_data.columns = [int(c) for c in df_data.columns]\n",
    "\n",
    "X0_test = df_data[sorted(df_data.columns)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = clf.predict_proba(X0_test)[:, 1]\n",
    "p1 = clf.predict_proba(X1_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 100\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.hist(p0, bins=100, range=(0,1), alpha=0.5, log=True, density=True);\n",
    "plt.hist(p1, bins=100, range=(0,1), alpha=0.5, log=True, density=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 100\n",
    "binning = np.linspace(0, 1, nbins+1)\n",
    "\n",
    "hist_p0, bin_edges = np.histogram(p0, binning)\n",
    "hist_p1, bin_edges = np.histogram(p1, binning)\n",
    "\n",
    "def poisson_uncertainty(n):\n",
    "    sigman = np.sqrt(n)\n",
    "    # correct poisson counts of zero.\n",
    "    sigman[sigman == 0] = 1.\n",
    "    return sigman\n",
    "\n",
    "def fraction_and_uncertainty(a, b, sigma_a, sigma_b):\n",
    "    absum = a+b\n",
    "    #frac_a = np.divide(a, absum, out=np.zeros_like(a), where=(absum) != 0)\n",
    "    #frac_b = np.divide(b, absum, out=np.zeros_like(b), where=(absum) != 0)\n",
    "    frac_a = a / (a + b)\n",
    "    frac_b = b / (a + b)\n",
    "    sigma_fa2 = np.power(frac_b * sigma_a, 2) / np.power(a + b, 2)  +  np.power(frac_a * sigma_b, 2) / np.power(a + b, 2)\n",
    "    return frac_a, np.sqrt(sigma_fa2)\n",
    "\n",
    "rest_p0 = np.sum(hist_p0) - hist_p0\n",
    "rest_p1 = np.sum(hist_p1) - hist_p1\n",
    "\n",
    "sigma_bin0 = poisson_uncertainty(hist_p0)\n",
    "sigma_rest0 = poisson_uncertainty(rest_p0)\n",
    "\n",
    "sigma_bin1 = poisson_uncertainty(hist_p1)\n",
    "sigma_rest1 = poisson_uncertainty(rest_p1)\n",
    "\n",
    "frac0, sigma_frac0 = fraction_and_uncertainty(hist_p0, rest_p0, sigma_bin0, sigma_rest0)\n",
    "frac1, sigma_frac1 = fraction_and_uncertainty(hist_p1, rest_p1, sigma_bin1, sigma_rest1)\n",
    "\n",
    "p1calib, sigma_p1calib = fraction_and_uncertainty(frac1, frac0, sigma_frac1, sigma_frac0)\n",
    "\n",
    "sample_weight = 1 / (sigma_p1calib * sigma_p1calib)\n",
    "sample_weight /= min(sample_weight)\n",
    "\n",
    "#sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we recalibrate per probability bin. NO interpolation (not valid in highest bin)\n",
    "#hist_p0, bin_edges = np.histogram(p0, bins=nbins, range=(0, 1))\n",
    "#hist_p1, bin_edges = np.histogram(p2, bins=nbins, range=(0, 1)) #### !!!! p2\n",
    "bin_centers = bin_edges[:-1] + 0.5/nbins\n",
    "\n",
    "hnorm_p0 = hist_p0 / sum(hist_p0)\n",
    "hnorm_p1 = hist_p1 / sum(hist_p1)\n",
    "hnorm_sum = hnorm_p0 + hnorm_p1\n",
    "p1cb = np.divide(hnorm_p1, hnorm_sum, out=np.zeros_like(hnorm_p1), where=hnorm_sum != 0)\n",
    "# self.p1cb = p1cb, bin_centers\n",
    "\n",
    "# use isotonic regression to smooth out potential fluctuations in the p1 values\n",
    "# isotonic regression assumes that p1 can only be a rising function.\n",
    "# Iâ€™m assuming that if a classifier predicts a higher probability, the calibrated probability\n",
    "# will also be higher. This may not always be right, but I think generally it is a safe one.\n",
    "iso_reg = IsotonicRegression(y_min=0, y_max=1).fit(bin_centers, p1calib, sample_weight)\n",
    "p1pred = iso_reg.predict(bin_centers)\n",
    "\n",
    "# calibrated probabilities\n",
    "p1f_ = interpolate.interp1d(\n",
    "    bin_edges[:-1], \n",
    "    p1pred, \n",
    "    kind='previous', \n",
    "    bounds_error=False, \n",
    "    fill_value=\"extrapolate\"\n",
    ")\n",
    "\n",
    "p1pred = p1f_(bin_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1lin = p1f_(bin_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.plot(bin_centers, p1cb, label='p1cb')\n",
    "plt.plot(bin_centers, p1pred, label='p1pred')\n",
    "plt.plot(bin_centers, bin_centers, label='bin_centers')\n",
    "plt.plot(bin_centers, p1lin, label='p1lin')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxp1 = p1f_(0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_weight = maxp1 / (1. - maxp1)\n",
    "max_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation - part 1: check if reweighting works okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# sample data from BN\n",
    "inference = BayesianModelSampling(model)\n",
    "\n",
    "df_data = inference.forward_sample(size=250000, return_type='dataframe')\n",
    "\n",
    "df_data.columns = [int(c) for c in df_data.columns]\n",
    "\n",
    "X_test = df_data[sorted(df_data.columns)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = clf.predict_proba(X_test)[:, 1]\n",
    "nominator = p1f_(p0)\n",
    "denominator = 1 - nominator\n",
    "weight = np.divide(nominator, denominator, out=np.ones_like(nominator), where=denominator != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test), sum(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "keep = weight == max_weight\n",
    "same = weight != max_weight\n",
    "ratio = (250000 - np.sum(weight[same])) / np.sum(weight[keep])\n",
    "np.sum(weight[same]), np.sum(weight[keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(weight, bins=100, log=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data, sample_weights = self._sample_no_transform(n_samples, random_state)\n",
    "pop = np.asarray(range(X_test.shape[0]))\n",
    "probs = weight/np.sum(weight)\n",
    "sample = choices(pop, probs, k=X_test.shape[0])\n",
    "Xtrans = X_test[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = clf.predict_proba(Xtrans)[:, 1]\n",
    "p1 = clf.predict_proba(X1_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.hist(p0, bins=100, range=(0,1), alpha=0.5, density=True); #, weights=weight)#, log=True)\n",
    "plt.hist(p1, bins=100, range=(0,1), alpha=0.5, density=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation - part 2: plot distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.hist(X_test[:, i], bins=100, range=(0,1), alpha=0.5, density=True);#, log=True)\n",
    "plt.hist(X1_test[:, i], bins=100, range=(0,1), alpha=0.5, density=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation part 3: check number of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "df_data = inference.forward_sample(size=500000, return_type='dataframe')\n",
    "df_data.columns = [int(c) for c in df_data.columns]\n",
    "X10k = df_data[sorted(df_data.columns)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = clf.predict_proba(X10k)[:, 1]\n",
    "nominator = p1f_(p0)\n",
    "denominator = 1 - nominator\n",
    "weight = np.divide(nominator, denominator, out=np.ones_like(nominator), where=denominator != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = np.asarray(range(X10k.shape[0]))\n",
    "probs = weight/np.sum(weight)\n",
    "sample = choices(pop, probs, k=X10k.shape[0])\n",
    "Xtrans = X10k[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, c = np.unique(Xtrans, axis=0, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.sort(c)[::-1] / 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, c = np.unique(data, axis=0, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = np.sort(c)[::-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.bar(list(range(40)), c2[:40], alpha=0.5)\n",
    "plt.bar(list(range(40)), counts[:40], alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run sdgym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(Xtrans)\n",
    "df.to_csv(f'{dataset_name}_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KDECopulaNNPdf_RoundCategorical(real_data, categorical_columns, ordinal_columns, times=None):\n",
    "    df = pd.read_csv(f'{dataset_name}_test.csv')\n",
    "    data = df.values[:real_data.shape[0]]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdgym.synthesizers import (\n",
    "    CLBNSynthesizer, CTGANSynthesizer, IdentitySynthesizer, IndependentSynthesizer,\n",
    "    MedganSynthesizer, PrivBNSynthesizer, TableganSynthesizer, TVAESynthesizer,\n",
    "    UniformSynthesizer, VEEGANSynthesizer)\n",
    "\n",
    "all_synthesizers = [\n",
    "    IdentitySynthesizer,\n",
    "    IndependentSynthesizer,\n",
    "    PrivBNSynthesizer,\n",
    "    KDECopulaNNPdf_RoundCategorical,\n",
    "#     CTGANSynthesizer,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores = sdgym.run(synthesizers=all_synthesizers, datasets=[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
